#!/usr/bin/env python3
import argparse
import subprocess
import os
import sys
import shutil
import time

# Configuration
COMPOSE_FILE = "docker-compose.yml"
VARIANTS = ["core", "kasm", "vnc"]

# ANSI Colors
class Colors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

def print_header(msg):
    print(f"{Colors.HEADER}{Colors.BOLD}>>> {msg}{Colors.ENDC}")

def print_success(msg):
    print(f"{Colors.OKGREEN}✔ {msg}{Colors.ENDC}")

def print_error(msg):
    print(f"{Colors.FAIL}✘ {msg}{Colors.ENDC}")

def print_info(msg):
    print(f"{Colors.OKCYAN}ℹ {msg}{Colors.ENDC}")

def run_command(cmd, cwd=None, capture=False, check=True):
    """Runs a shell command."""
    if not capture:
        print(f"{Colors.OKBLUE}$ {cmd}{Colors.ENDC}")
    try:
        if capture:
            result = subprocess.run(cmd, shell=True, cwd=cwd, check=check, capture_output=True, text=True)
            return result.stdout.strip()
        else:
            subprocess.check_call(cmd, shell=True, cwd=cwd)
    except subprocess.CalledProcessError as e:
        if check:
            print_error(f"Command failed with exit code {e.returncode}")
            if capture:
                print(e.stderr)
            sys.exit(e.returncode)
        else:
            raise e

def get_uid_gid_user():
    """Returns the current user's UID, GID, and Username."""
    import pwd
    uid = os.getuid()
    return uid, os.getgid(), pwd.getpwuid(uid).pw_name

def check_prereqs(args):
    """Checks if Docker and Docker Compose are installed."""
    print_header("Checking Prerequisites")

    # Check Docker
    if shutil.which("docker"):
        print_success("Docker is installed")
    else:
        print_error("Docker is NOT installed. Please install Docker first.")
        sys.exit(1)

    # Check Docker Compose
    try:
        run_command("docker compose version", capture=True)
        print_success("Docker Compose is installed")
    except:
        print_error("Docker Compose is NOT installed or not accessible.")
        sys.exit(1)

    # Check if docker daemon is running
    try:
        run_command("docker info", capture=True)
        print_success("Docker Daemon is running")
    except:
        print_error("Docker Daemon is NOT running. Please start Docker.")
        sys.exit(1)

def build(args):
    """Builds the specified variant(s)."""
    targets = args.variant if args.variant else VARIANTS
    if "all" in targets:
        targets = VARIANTS

    print_header(f"Building Variants: {', '.join(targets)}")

    for target in targets:
        print_info(f"Building {target}...")
        run_command(f"docker compose -f {COMPOSE_FILE} build {target}")

    print_success("Build complete!")

def install(args):
    """Alias for build, but maybe in future pulls images."""
    # For now, we build locally.
    build(args)

def up(args):
    """Starts the specified variant (docker compose up)."""
    target = args.variant

    # Check prereqs first
    if not args.skip_check:
        check_prereqs(args)

    uid, gid, username = get_uid_gid_user()

    print_header(f"Starting {target}")
    print_info(f"Mapping User: {username} (UID={uid}, GID={gid})")

    # Stop other variants to avoid port conflicts?
    # Optional, but good for "out-of-the-box" experience.
    # Let's just warn or try to run. Docker compose handles recreation.

    ssh_port = args.ssh_port
    kasm_port = args.kasm_port
    vnc_port = args.vnc_port
    novnc_port = args.novnc_port

    compose_files = f"-f {COMPOSE_FILE}"
    if args.gpu:
        if not os.path.exists("docker-compose.gpu.yml"):
             print_error("docker-compose.gpu.yml not found. Cannot enable GPU.")
             sys.exit(1)
        compose_files += " -f docker-compose.gpu.yml"
        compose_files += " -f docker-compose.gpu.yml"
        print_info("GPU Support Enabled")

    # Git Context Sharing
    git_compose = generate_git_compose(username)
    if git_compose:
        compose_files += f" -f {git_compose}"
        print_info("Git Context Sharing Enabled")

    password = args.password


    # Auto-Port Assignment Logic
    # If using a custom name AND ports are default, switch to ephemeral ports (0)
    # UNLESS the user explicitly passed the port flag.
    if args.name != "sanity-gravity":
        # Check if user explicitly set ports by looking at sys.argv
        # This avoids the issue where argparse defaults mask the user's intent.

        args_str = " ".join(sys.argv)

        # Helper to check if a flag was used
        def is_flag_set(flags):
            for f in flags:
                if f in sys.argv:
                    return True
            return False

        if not is_flag_set(["--ssh-port", "-p"]) and args.ssh_port == "2222": ssh_port = "0"
        if not is_flag_set(["--kasm-port"]) and args.kasm_port == "8444": kasm_port = "0"
        if not is_flag_set(["--vnc-port"]) and args.vnc_port == "5901": vnc_port = "0"
        if not is_flag_set(["--novnc-port"]) and args.novnc_port == "6901": novnc_port = "0"

    env_vars = f"SSH_HOST_PORT={ssh_port} KASM_PORT={kasm_port} VNC_PORT={vnc_port} NOVNC_PORT={novnc_port} HOST_UID={uid} HOST_GID={gid} HOST_USER={username} HOST_PASSWORD={password} VNC_PW={password}"

    if args.workspace:
        workspace_path = os.path.abspath(args.workspace)
        env_vars += f" WORKSPACE_DIR={workspace_path}"
        print_info(f"Using Workspace: {workspace_path}")

    project_name = args.name
    print_info(f"Project Name: {project_name}")

    try:
        run_command(f"{env_vars} docker compose -p {project_name} {compose_files} up -d {target}")

        # Retrieve actual ports if they were ephemeral
        if ssh_port == "0" or kasm_port == "0" or vnc_port == "0" or novnc_port == "0":
            print_info("Resolving ephemeral ports...")
            # We need to query docker compose port
            # Service names: core, kasm, vnc
            # Internal ports: 22, 8444, 5901, 6901

            def get_port(service, internal):
                try:
                    out = run_command(f"docker compose -p {project_name} {compose_files} port {service} {internal}", capture=True)
                    # Output format: 0.0.0.0:32768
                    if ":" in out:
                        return out.split(":")[-1]
                except:
                    pass
                return "?"

            if target in ["core", "kasm", "vnc"]:
                ssh_port = get_port(target, "22")

            if target == "kasm":
                kasm_port = get_port("kasm", "8444")

            if target == "vnc":
                vnc_port = get_port("vnc", "5901")
                novnc_port = get_port("vnc", "6901")

    except SystemExit:
        return

    print_success(f"{target} is running.")

    if target == "kasm":
        print(f"\n{Colors.BOLD}Access KasmVNC:{Colors.ENDC}")
        print(f"  URL:      {Colors.UNDERLINE}https://localhost:{kasm_port}{Colors.ENDC}")
        print(f"  SSH:      ssh -p {ssh_port} {username}@localhost")
        print(f"  User:     {username}")
        print(f"  Pass:     {password}")
    elif target == "vnc":
        print(f"\n{Colors.BOLD}Access VNC:{Colors.ENDC}")
        print(f"  VNC Client: localhost:{vnc_port}")
        print(f"  noVNC Web:  {Colors.UNDERLINE}http://localhost:{novnc_port}/vnc.html{Colors.ENDC}")
        print(f"  SSH:        ssh -p {ssh_port} {username}@localhost")
        print(f"  Password:   {password}")

    elif target == "core":
        print(f"\n{Colors.BOLD}Access Core:{Colors.ENDC}")
        print(f"  SSH:        ssh -p {ssh_port} {username}@localhost")
        print(f"  Pass:       {password}")
        print(f"  Shell:      docker exec -it -u {username} sanity-gravity-core-1 /bin/bash")

    # Sync Configuration
    container_name = f"{project_name}-{target}-1"
    sync_config(project_name, container_name, username)

def generate_git_compose(username):
    """Generates a docker-compose override to mount git config and ssh agent."""
    print_info("Checking for Git configuration...")

    home = os.path.expanduser("~")
    gitconfig = os.path.join(home, ".gitconfig")
    ssh_auth_sock = os.environ.get("SSH_AUTH_SOCK")

    volumes = []
    environment = {}

    if os.path.exists(gitconfig):
        # Mount as read-only to prevent accidental corruption
        volumes.append(f"      - {gitconfig}:/home/{username}/.gitconfig")
        print_success(f"Found .gitconfig")
    else:
        print_info(".gitconfig not found on host.")

    if ssh_auth_sock and os.path.exists(ssh_auth_sock):
        # Mount SSH Agent Socket
        volumes.append(f"      - {ssh_auth_sock}:/tmp/ssh-agent.sock")
        environment["SSH_AUTH_SOCK"] = "/tmp/ssh-agent.sock"
        print_success(f"Found SSH Agent ({ssh_auth_sock})")
    else:
        print_warning("SSH Agent not found. Git operations requiring SSH keys might fail.")

    if not volumes:
        print_info("Git Context Sharing skipped (no config found).")
        return None

    # Generate YAML content manually to avoid dependencies
    content = "services:\n"
    for variant in VARIANTS:
        content += f"  {variant}:\n"

        if volumes:
            content += "    volumes:\n"
            for vol in volumes:
                content += f"{vol}\n"

        if environment:
            content += "    environment:\n"
            for k, v in environment.items():
                content += f"      - {k}={v}\n"

    config_dir = "config"
    os.makedirs(config_dir, exist_ok=True)
    output_file = os.path.join(config_dir, "docker-compose.git.yml")

    with open(output_file, "w") as f:
        f.write(content)

    return output_file

def sync_config(project_name, container_name, username):
    """Syncs Antigravity configuration to the container."""
    print_header("Configuration Sync")

    config_dir = "config"
    host_gemini_dir = os.path.expanduser("~/.gemini")

    # Check if project config exists
    if not os.path.exists(config_dir):
        # Check for non-interactive mode
        if not sys.stdin.isatty():
            print_warning("Non-interactive mode detected. Skipping configuration initialization.")
            return

        print_info("No project configuration found in ./config/")
        print(f"{Colors.BOLD}Select an option to initialize configuration:{Colors.ENDC}")
        print("  [A] Copy from Host (~/.gemini/) - Recommended")
        print("  [B] Create Empty (Initialize empty config)")
        print("  [C] Skip (Use container defaults)")

        choice = input(f"{Colors.OKBLUE}Enter choice [A/b/c]: {Colors.ENDC}").strip().lower()

        if choice in ["", "a"]:
            print_info("Copying configuration from host...")
            os.makedirs(config_dir, exist_ok=True)

            # Copy GEMINI.md
            src_gemini = os.path.join(host_gemini_dir, "GEMINI.md")
            if os.path.exists(src_gemini):
                shutil.copy2(src_gemini, os.path.join(config_dir, "GEMINI.md"))
                print_success("Copied GEMINI.md")
            else:
                print_warning("Host GEMINI.md not found, skipping.")

            # Copy settings.json
            src_settings = os.path.join(host_gemini_dir, "settings.json")
            if os.path.exists(src_settings):
                shutil.copy2(src_settings, os.path.join(config_dir, "settings.json"))
                print_success("Copied settings.json")

        elif choice == "b":
            print_info("Creating empty configuration...")
            os.makedirs(config_dir, exist_ok=True)
            with open(os.path.join(config_dir, "GEMINI.md"), "w") as f:
                f.write("# Project GEMINI.md\n")
            with open(os.path.join(config_dir, "settings.json"), "w") as f:
                f.write("{}")
            print_success("Created empty config files.")

        else:
            print_info("Skipping configuration sync.")
            return

    # Perform Sync to Container
    if os.path.exists(config_dir):
        print_info(f"Syncing ./config/ to container ({container_name})...")

        # Wait for user to be created (Race condition fix)
        user_ready = False
        for i in range(30): # Wait up to 30 seconds
            # Check if user exists inside container
            # We use check=False to avoid printing errors/exiting if user doesn't exist yet
            out = run_command(f"docker exec {container_name} id -u {username}", capture=True, check=False)
            if out and out.strip().isdigit():
                user_ready = True
                break
            time.sleep(1)

        if not user_ready:
            print_warning(f"User '{username}' not found in container after 30s. Sync might fail.")

        target_dir = f"/home/{username}/.gemini"

        # Ensure target directory exists
        run_command(f"docker exec {container_name} mkdir -p {target_dir}")

        # Copy config files
        # We copy the whole directory content which now only contains what we put in it (GEMINI.md, settings.json)
        run_command(f"docker cp {config_dir}/. {container_name}:{target_dir}/")

        # Fix permissions (docker cp makes it root owned)
        run_command(f"docker exec {container_name} chown -R {username}:{username} {target_dir}")

        print_success("Configuration synced successfully.")

def print_warning(msg):
    print(f"{Colors.WARNING}⚠ {msg}{Colors.ENDC}")

def get_project_env(project_name):
    """Retrieves environment variables from a running container of the project."""
    # Try to find any container belonging to this project
    # We try typical service names: core, kasm, vnc
    for service in VARIANTS:
        container_name = f"{project_name}-{service}-1"

        # Check if container exists (silently)
        # We use check=False so it doesn't print errors or exit if not found
        check_res = run_command(f"docker inspect {container_name}", capture=True, check=False)
        if check_res == "": # If capture=True and fails, run_command might return empty string or error msg depending on impl
             # Actually run_command implementation:
             # if capture: return result.stdout.strip()
             # if check=False, it raises error? No.
             # Wait, run_command implementation:
             # if check=False: raise e (if capture=False)
             # if capture=True: result = subprocess.run(..., check=check ...)
             pass

        # Let's look at run_command again.
        # if capture: result = subprocess.run(..., check=check, ...)
        # if check=False, subprocess.run won't raise CalledProcessError.
        # It returns CompletedProcess.
        # But my run_command implementation returns result.stdout.strip().
        # So if it fails, it returns stdout (which might be empty).
        # But stderr is printed? No, capture_output=True captures both.
        # But I only return stdout.

        # To be safe and clean, let's just try to inspect and ignore failure.
        try:
            # We use a direct subprocess call for existence check to avoid run_command's noise
            subprocess.check_call(f"docker inspect {container_name}", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        except subprocess.CalledProcessError:
            continue

        # If we are here, container exists. Get Env.
        try:
            out = run_command(f"docker inspect -f '{{{{range .Config.Env}}}}{{println .}}{{{{end}}}}' {container_name}", capture=True, check=False)
            if not out: continue

            env_map = {}
            for line in out.splitlines():
                if "=" in line:
                    key, val = line.split("=", 1)
                    # We only care about our specific variables
                    if key in ["SSH_HOST_PORT", "KASM_PORT", "VNC_PORT", "NOVNC_PORT", "HOST_UID", "HOST_GID", "HOST_USER", "HOST_PASSWORD", "VNC_PW"]:
                        env_map[key] = val

            # If we found relevant vars, return them.
            # If not (e.g. empty), keep looking?
            if env_map:
                return env_map
        except:
            continue

    return {}

def run_compose_cmd(args, action, check_existence=False):
    """Helper to run docker compose commands with recovered environment."""
    project_name = args.name

    # Check existence if requested (mainly for 'down')
    if check_existence:
        active_projects = get_active_projects()
        if project_name not in active_projects:
            print_warning(f"Project '{project_name}' not found.")
            if active_projects:
                print(f"Active projects: {', '.join(active_projects)}")
                print(f"{Colors.OKBLUE}Tip: Use --name <project> to specify a project.{Colors.ENDC}")
            else:
                print("No active Sanity-Gravity projects found.")
            return

    # Recover Env
    env_vars = get_project_env(project_name)
    env_str = " ".join([f"{k}={v}" for k, v in env_vars.items()])

    # If we couldn't find the container (maybe it's already stopped or broken),
    # we might still want to try 'down' with default/empty vars just in case.
    # But for 'down', if we found nothing, maybe there's nothing to down?
    # Not necessarily, 'docker compose down' also removes networks/volumes which might exist without containers.
    # However, without the env vars, 'down' might not work perfectly if config differs.
    # We'll proceed with what we have.

    print_header(f"{action.capitalize()}ing Sandbox ({project_name})")

    cmd = f"{env_str} docker compose -p {project_name} -f {COMPOSE_FILE} {action}"
    run_command(cmd)

    if action == "down":
        print_success("All containers removed.")
    elif action == "stop":
        print_success("Containers stopped (data preserved).")
    elif action == "start":
        print_success("Containers started.")
    elif action == "restart":
        print_success("Containers restarted.")

def down(args):
    """Stops and removes all sandbox containers (docker compose down)."""
    run_compose_cmd(args, "down", check_existence=True)

def stop(args):
    """Stops sandbox containers without removing them (docker compose stop)."""
    run_compose_cmd(args, "stop")

def start(args):
    """Starts existing stopped containers (docker compose start)."""
    run_compose_cmd(args, "start")

def restart(args):
    """Restarts sandbox containers (docker compose restart)."""
    run_compose_cmd(args, "restart")

def get_active_projects():
    """Returns a list of active Sanity-Gravity project names."""
    try:
        # List all containers with docker-compose project label AND filter by our image name
        # We look for containers using images starting with 'sanity-gravity'
        cmd = "docker ps --filter 'ancestor=sanity-gravity:core' --filter 'ancestor=sanity-gravity:kasm' --filter 'ancestor=sanity-gravity:vnc' --format '{{.Label \"com.docker.compose.project\"}}'"

        # Note: multiple filters in docker ps are usually AND logic for different keys, but OR logic for same key?
        # Actually 'ancestor' filter is additive (OR) in newer docker versions? No, usually AND.
        # Wait, docker ps filters are AND. So we can't filter multiple ancestors in one go if they are mutually exclusive.
        # We need to run multiple commands or filter in python.

        # Let's get ALL compose projects first (like before) but then filter them.
        # Or better: get all containers with their project AND image, then filter in Python.

        cmd = "docker ps --format '{{.Label \"com.docker.compose.project\"}}|{{.Image}}'"
        output = run_command(cmd, capture=True, check=False)
        if not output:
            return []

        projects = set()
        for line in output.splitlines():
            parts = line.split('|')
            if len(parts) == 2:
                project, image = parts
                if project and image.startswith("sanity-gravity"):
                    projects.add(project)

        return sorted(list(projects))
    except:
        return []

def status(args):
    """Shows status of sandbox containers."""
    target_project = args.name

    # If the user specifically asked for a name other than default, just show that.
    # If default, we scan for all.

    active_projects = get_active_projects()

    if target_project != "sanity-gravity" and target_project not in active_projects:
         print_warning(f"Project '{target_project}' not found in active projects.")

    projects_to_show = []
    if target_project == "sanity-gravity":
        # Show all active projects
        if not active_projects:
             print_info("No active Sanity-Gravity instances found.")
             return
        projects_to_show = active_projects
    else:
        projects_to_show = [target_project]

    for project in projects_to_show:
        print_header(f"Sandbox Status ({project})")
        try:
            # We use 'docker compose ps' to get a nice table
            # We need to find the compose file. Assuming it's in current dir as docker-compose.yml
            # If the project was started from elsewhere, this might fail if we rely on the file for 'ps'
            # But 'docker compose -p <name> ps' usually works if the project exists in docker engine

            # Note: 'docker compose ps' might require the compose file to be present to know the service definitions
            # strictly speaking, but often works for listing.
            # Let's try 'docker ps' filtered by project for a more robust generic view if compose ps fails,
            # but 'docker compose ps' is prettier.

            output = run_command(f"docker compose -p {project} -f {COMPOSE_FILE} ps", capture=True, check=False)
            if output:
                print(output)
            else:
                print_info("  No containers running.")

            # Also try to show ports nicely if possible
            # This is a bit hacky without full introspection, but 'ps' usually shows ports.
            print("")
        except:
            print_error(f"Failed to get status for {project}")

def test_suite(args):
    """Runs the test suite using pytest."""
    try:
        # Check if pytest is installed
        import pytest
    except ImportError:
        print_error("pytest is not installed. Please run: pip install pytest requests")
        sys.exit(1)

    print_header("Running Test Suite")

    # Nuclear Option: Disable all plugin autoloading to avoid ROS2 environment pollution
    os.environ["PYTEST_DISABLE_PLUGIN_AUTOLOAD"] = "1"

    # Arguments for pytest
    # -v: Verbose
    pytest_args = ["-v"]
    if args.target:
        pytest_args.append(args.target)

    # Run pytest
    exit_code = pytest.main(pytest_args)
    if exit_code != 0:
        sys.exit(exit_code)

def list_variants(args):
    """Lists available variants."""
    print_header("Available Variants")
    for v in VARIANTS:
        print(f" - {Colors.BOLD}{v}{Colors.ENDC}")

def main():
    parser = argparse.ArgumentParser(description="Antigravity Sandbox CLI")
    subparsers = parser.add_subparsers(dest="command", help="Command to execute")

    # Check Command
    parser_check = subparsers.add_parser("check", help="Check prerequisites")
    parser_check.set_defaults(func=check_prereqs)

    # Build Command
    parser_build = subparsers.add_parser("build", help="Build sandbox images")
    parser_build.add_argument("variant", nargs="*", help="Variant to build (default: all)", default=["all"])
    parser_build.set_defaults(func=build)

    # Install Command (Alias)
    parser_install = subparsers.add_parser("install", help="Install/Build sandbox environment")
    parser_install.add_argument("variant", nargs="*", help="Variant to install (default: all)", default=["all"])
    parser_install.set_defaults(func=install)

    # Up Command (formerly Run)
    parser_up = subparsers.add_parser("up", help="Create and start sandbox (docker compose up)")
    parser_up.add_argument("--variant", "-v", required=True, help="Variant to run", choices=VARIANTS)
    parser_up.add_argument("--ssh-port", "-p", default="2222", help="Host port for SSH (default: 2222)")
    parser_up.add_argument("--kasm-port", default="8444", help="Host port for KasmVNC (default: 8444)")
    parser_up.add_argument("--vnc-port", default="5901", help="Host port for VNC (default: 5901)")
    parser_up.add_argument("--novnc-port", default="6901", help="Host port for noVNC (default: 6901)")
    parser_up.add_argument("--password", default="antigravity", help="Password for SSH/VNC (default: antigravity)")
    parser_up.add_argument("--gpu", action="store_true", help="Enable Nvidia GPU support (requires docker-compose.gpu.yml)")
    parser_up.add_argument("--skip-check", action="store_true", help="Skip prerequisite checks")
    parser_up.add_argument("--workspace", "-w", default=None, help="Path to workspace directory (default: ./workspace)")
    parser_up.add_argument("--name", "-n", default="sanity-gravity", help="Project name for multi-instance support (default: sanity-gravity)")
    parser_up.set_defaults(func=up)

    # Run Command (Alias for Up)
    parser_run = subparsers.add_parser("run", help="Alias for 'up'")
    parser_run.add_argument("--variant", "-v", required=True, help="Variant to run", choices=VARIANTS)
    parser_run.add_argument("--ssh-port", "-p", default="2222", help="Host port for SSH (default: 2222)")
    parser_run.add_argument("--kasm-port", default="8444", help="Host port for KasmVNC (default: 8444)")
    parser_run.add_argument("--vnc-port", default="5901", help="Host port for VNC (default: 5901)")
    parser_run.add_argument("--novnc-port", default="6901", help="Host port for noVNC (default: 6901)")
    parser_run.add_argument("--password", default="antigravity", help="Password for SSH/VNC (default: antigravity)")
    parser_run.add_argument("--gpu", action="store_true", help="Enable Nvidia GPU support (requires docker-compose.gpu.yml)")
    parser_run.add_argument("--skip-check", action="store_true", help="Skip prerequisite checks")
    parser_run.add_argument("--workspace", "-w", default=None, help="Path to workspace directory (default: ./workspace)")
    parser_run.add_argument("--name", "-n", default="sanity-gravity", help="Project name for multi-instance support (default: sanity-gravity)")
    parser_run.set_defaults(func=up)

    # Down Command (formerly Stop)
    parser_down = subparsers.add_parser("down", help="Stop and remove containers (docker compose down)")
    parser_down.add_argument("--name", "-n", default="sanity-gravity", help="Project name (default: sanity-gravity)")
    parser_down.set_defaults(func=down)

    # Stop Command (New behavior)
    parser_stop = subparsers.add_parser("stop", help="Stop containers without removing (docker compose stop)")
    parser_stop.add_argument("--name", "-n", default="sanity-gravity", help="Project name (default: sanity-gravity)")
    parser_stop.set_defaults(func=stop)

    # Start Command
    parser_start = subparsers.add_parser("start", help="Start stopped containers (docker compose start)")
    parser_start.add_argument("--name", "-n", default="sanity-gravity", help="Project name (default: sanity-gravity)")
    parser_start.set_defaults(func=start)

    # Restart Command
    parser_restart = subparsers.add_parser("restart", help="Restart containers (docker compose restart)")
    parser_restart.add_argument("--name", "-n", default="sanity-gravity", help="Project name (default: sanity-gravity)")
    parser_restart.set_defaults(func=restart)

    # Status Command
    parser_status = subparsers.add_parser("status", help="Show sandbox status")
    parser_status.add_argument("--name", "-n", default="sanity-gravity", help="Project name (default: sanity-gravity)")
    parser_status.set_defaults(func=status)

    # List Command
    parser_list = subparsers.add_parser("list", help="List available variants")
    parser_list.set_defaults(func=list_variants)

    # Test Command
    parser_test = subparsers.add_parser("test", help="Run test suite")
    parser_test.add_argument("target", nargs="?", help="Specific test target (e.g., tests/test_core.py)")
    parser_test.set_defaults(func=test_suite)

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        sys.exit(1)

    args.func(args)

if __name__ == "__main__":
    main()
